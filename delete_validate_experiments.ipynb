{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37f3cbae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "464\n",
      "464\n",
      "464\n",
      "464\n",
      "464\n",
      "464\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n",
      "60\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import copy\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST/', \"results_FashionMNIST_CNN/\", 'results_mnist/', 'results_MNIST_CNN/', 'results_News/', 'results_SVM/', 'results_FashionMNIST_recalibrator/', \"results_FashionMNIST_CNN_recalibrator/\", 'results_mnist_recalibrator/', 'results_MNIST_CNN_recalibrator/', 'results_News_recalibrator/', 'results_SVM_recalibrator/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    subdirect_count_complete = 0\n",
    "    subdirect_missing = 0\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            has_params = False\n",
    "            has_metrics = False\n",
    "            has_dataset = False\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"param\") != -1:\n",
    "                    has_params = True\n",
    "                elif filename.find(\"metric\") != -1:\n",
    "                    has_metrics = True\n",
    "                elif filename.find(\"dataset\") != -1:\n",
    "                    has_data = True\n",
    "            if not has_params or not has_metrics or not has_data:\n",
    "                \n",
    "                subdirect_missing += 1\n",
    "                    #if params['acquisition'] == \"TS\":\n",
    "                #shutil.rmtree(folder)\n",
    "            else:\n",
    "                #for tag in foldername.split(\"--\"):\n",
    "                    #if tag.find(\"seed\") != -1:\n",
    "                        #if int(tag.split(\"-\")[1]) > 29:\n",
    "                            #shutil.rmtree(folder)\n",
    "                subdirect_count_complete += 1\n",
    "    print(subdirect_count_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "63a0c293",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Instantaneous regret of pool rankings from real_data with vanilla uncertanties.\n",
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "exp_dict = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "main_directory=\"./results_real_data/\"\n",
    "subdirectories = ['results_FashionMNIST/', \"results_FashionMNIST_CNN/\", 'results_mnist/', 'results_MNIST_CNN/', 'results_News/', 'results_SVM/']\n",
    "for subdirectory in subdirectories:\n",
    "    full_path = os.path.join(main_directory, subdirectory)\n",
    "    for foldername in os.listdir(full_path):\n",
    "        folder = os.path.join(full_path, foldername)\n",
    "        if os.path.isdir(folder):\n",
    "            for filename in os.listdir(folder):\n",
    "                if filename.find(\"parameters\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    params = json.load(json_file)\n",
    "                elif filename.find(\"metrics\") != -1:\n",
    "                    json_file = open(os.path.join(folder, filename))\n",
    "                    metrics = json.load(json_file)\n",
    "            if params['bo'] == True:\n",
    "                exp_dict['surrogate'].append(params['surrogate'])\n",
    "                exp_dict['acquisition'].append(params['acquisition'])\n",
    "                exp_dict['data'].append(params['data_name'])\n",
    "                exp_dict['dist_nearest_train'].append(metrics['next_sample_train_distance'])\n",
    "                exp_dict['inst_regret_test'].append(metrics['y_regret_test'])\n",
    "                exp_dict['inst_regret_pool'].append(metrics['y_regret_pool'])\n",
    "                exp_dict['tot_regret_test'].append(np.cumsum(metrics['y_regret_test']))\n",
    "                exp_dict['tot_regret_pool'].append(np.cumsum(metrics['y_regret_pool']))\n",
    "                exp_dict['x_opt_dist_pool'].append(metrics['x_y_opt_dist_pool'])\n",
    "                exp_dict['x_opt_dist_test'].append(metrics['x_y_opt_dist_test'])\n",
    "                exp_dict['sharpness'].append(metrics['mean_sharpness'])\n",
    "                exp_dict['calibration_mse'].append(metrics['y_calibration_mse'])\n",
    "                exp_dict['seed'].append(params['seed'])\n",
    "df = pd.DataFrame.from_dict(exp_dict)\n",
    "processed_results = {'surrogate': [], 'acquisition': [], 'seed':[], 'data':[], 'dist_nearest_train_mean':[], 'inst_regret_test':[], 'inst_regret_pool':[], 'tot_regret_test':[], 'tot_regret_pool':[], 'calibration_mse':[], 'sharpness':[], 'x_opt_dist_test':[], 'x_opt_dist_pool':[]}\n",
    "for index, row in df.iterrows():\n",
    "    processed_results['surrogate'].append(row['surrogate'])\n",
    "    processed_results['acquisition'].append(row['acquisition'])\n",
    "    processed_results['data'].append(row['data'])\n",
    "    processed_results['seed'].append(row['seed'])\n",
    "    processed_results['dist_nearest_train_mean'].append(np.array(row['dist_nearest_train']).mean()) #Mean across one BO run.\n",
    "    processed_results['inst_regret_pool'].append(np.array(row['inst_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['inst_regret_test'].append(np.array(row['inst_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_test'].append(np.array(row['tot_regret_test'])[-1]) #Last iter.\n",
    "    processed_results['tot_regret_pool'].append(np.array(row['tot_regret_pool'])[-1]) #Last iter.\n",
    "    processed_results['calibration_mse'].append(np.array(row['calibration_mse']).mean()) #Mean Calibration MSE over run.\n",
    "    processed_results['sharpness'].append(np.array(row['sharpness']).mean()) #Mean sharpness over run.\n",
    "    processed_results['x_opt_dist_test'].append(np.array(row['x_opt_dist_test'])[-1])\n",
    "    processed_results['x_opt_dist_pool'].append(np.array(row['x_opt_dist_pool'])[-1])\n",
    "#Same seed and same dataset are ranked together.\n",
    "df = pd.DataFrame.from_dict(processed_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "051460cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 32, 34, 36, 38}\n"
     ]
    }
   ],
   "source": [
    "print(set(df.loc[df['surrogate']==\"RF\"]['seed']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23086e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
