{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem formulation\n",
    "\n",
    "We imagine a regression problem in $D$ dimensions with inputs $\\mathbf{x}_i \\in \\mathbb{R}^{D}$ and one-dimensional outputs $y_i \\in \\mathbb{R}$ on the form of\n",
    "\n",
    "$$ y_i = f(\\mathbf{x}_i) + \\epsilon(\\mathbf{x}_i) $$\n",
    "\n",
    "where $\\epsilon(\\mathbf{x}_i) = \\mathcal{N}(0,\\sigma_{\\epsilon}^2(\\mathbf{x}_i))$ is a noise term. If the variance $\\sigma^2(\\mathbf{x}_i) = \\sigma^2_{\\epsilon}$ is constant w.r.t. $\\mathbf{x}$ it is called *homoscedastic* noise and *heteroscedastic* if not. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to learn a probabilistic regression model $p_{\\theta}(y|\\mathbf{x})$, which for now we will assume is a normal distribution:\n",
    "\n",
    "$$p_{\\theta}(y|\\mathbf{x}) = \\mathcal{N}(y|\\mu(\\mathbf{x}),\\sigma_p^2(\\mathbf{x}))$$\n",
    "\n",
    "such as the case for Gaussian Processes (GPs) with predictive variance $\\sigma_p^2(\\mathbf{x})$. We want the model not only to have a good prediction error (e.g. a low mean squared error) but also has well-calibrated uncertainties $\\sigma_p^2(\\mathbf{x})$. We shall assume, the predictive variance has a (either analytical or approximal)  decomposition:\n",
    "\n",
    "$$\\sigma_p^2(\\mathbf{x}) = \\sigma_e^2(\\mathbf{x}) + \\sigma_a^2(\\mathbf{x})$$\n",
    "\n",
    "where $\\sigma_a^2(\\mathbf{x})$ is the *aleatoric* noise (irreducible inherent randomness in the data-generating process) and $\\sigma_e^2(\\mathbf{x})$ is the *epidemestic* noise (lack of knowledge, i.e. it can be reduced with better models or more data). Although the predictive variance from the GP has this exact explicit decomposition: \n",
    "$$\\sigma_p^2(\\mathbf{x})=\\underbrace{K(\\mathbf{x}_*,\\mathbf{x}_*)-K(\\mathbf{x}_*,\\mathbf{X})(K(\\mathbf{X},\\mathbf{X})+\\sigma_nI)^{-1}K(\\mathbf{X},\\mathbf{x}_*)}_{\\sigma^2_e} + \\underbrace{\\sigma_n^2I}_{\\sigma^2_a}$$\n",
    "\n",
    "and we are guarenteed that $\\sigma_n^2 \\xrightarrow{} \\sigma_{\\epsilon}^2$ in the limit of infinite samples, no such guarentee exists for finite samples and GPs are one of the few models to have this explicit decomposition. However, in this paper we argue that if a regressor has an explicit bias-variance decomposition we can at least approximate both aleatoric and epidemistic noise terms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bias-variance decomposition\n",
    "An often used loss function for regression models is the mean-squared-error (MSE) loss. With a model producing a prediction $\\hat{y}$ the expectation of MSE between $\\hat{y}$ and the observed $y$ can be decomposed (for brevity we have left out the dependence on input $\\mathbf{x}$):\n",
    "\\begin{split}\n",
    "\\mathbb{E}[(y-\\hat{y})^2] &= E[(f+\\epsilon-\\hat{y})^2] \\\\\n",
    "&= E[(f-\\hat{y})^2+2(f-\\hat{y})\\epsilon+\\epsilon^2]\\\\\n",
    "&= E[(f-\\hat{y})^2]+2E[(f-\\hat{y})\\epsilon]+E[\\epsilon^2]\\\\\n",
    "&= E\\left[\\left(f - E(\\hat{y}) + E(\\hat{y})-\\hat{y} \\right)^2 \\right] + 2E[(f-\\hat{y})\\epsilon]+\\sigma_{\\epsilon}^2 \\\\\n",
    "& = Var(\\hat{y}) + \\text{Bias}^2(\\hat{y}) + \\sigma_{\\epsilon}^2.\n",
    "\\end{split}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parameters import Parameters\n",
    "from src.experiment import Experiment\n",
    "from imports.general import *\n",
    "from imports.ml import *\n",
    "\n",
    "parameters = Parameters({\"surrogate\":\"RF\",\n",
    "\"experiment\":\"1\",\n",
    "\"acquisition\":\"EI\",\n",
    "\"data_name\":\"benchmark\",\n",
    "\"n_evals\":40,\n",
    "\"n_test\":1000,\n",
    "\"n_validation\":100,\n",
    "\"snr\":100,\n",
    "\"xi\":0.0,\n",
    "\"recalibrate\":False,\n",
    "\"bo\":True,\n",
    "\"extensive_metrics\":True,\n",
    "\"d\":3,\n",
    "\"recal_mode\":\"cv\",\n",
    "\"problem_idx\":5, \n",
    "\"seed\":0 ,\n",
    "\"n_initial\":10},mkdir=True)\n",
    "experiment = Experiment(parameters)\n",
    "experiment.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if parameters.d == 1:\n",
    "\tidx = np.argsort(experiment.dataset.data.X_test.squeeze())\n",
    "\tX_test = experiment.dataset.data.X_test[idx]\n",
    "\ty_test = experiment.dataset.data.y_test[idx]\n",
    "\tmu,sigma = experiment.optimizer.surrogate_object.predict(X_test)\n",
    "\tmu = mu.squeeze()\n",
    "\tsigma = 2*sigma.squeeze()\n",
    "\tfig = plt.figure()\n",
    "\tplt.plot(X_test, mu, marker=\".\")\n",
    "\tplt.fill_between(X_test.squeeze(), mu-sigma,mu+sigma,alpha=0.2)\n",
    "\tplt.plot(X_test, y_test,\"x\",alpha=0.2)\n",
    "\tplt.plot(experiment.dataset.data.X_train, experiment.dataset.data.y_train,\"o\")\n",
    "\n",
    "\tfig = plt.figure()\n",
    "\ta_vals = experiment.optimizer.acquisition_function(torch.from_numpy(np.expand_dims(X_test, 1))).cpu().detach().squeeze()\n",
    "\tplt.plot(X_test,a_vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Extensive investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Later when data should be loaded:\n",
    "cnx = sqlite3.connect('./results.db')\n",
    "print(\"Surrogate | cal | regret , regret_hat | tot_regret , tot_regret_hat\")\n",
    "for surrogate in [\"BNN\",\"GP\",\"RF\",\"DE\"]:\n",
    "\tdf = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='0' and surrogate='{surrogate}'\", cnx)\n",
    "\tcal_mu, cal_sigma = np.mean(df[[\"y_calibration_mse\"]].to_numpy()),np.std(df[[\"y_calibration_mse\"]].to_numpy())\n",
    "\n",
    "\tregret_mu, regret_sigma = np.mean(df[[\"f_regret\"]].to_numpy()),np.std(df[[\"f_regret\"]].to_numpy())\n",
    "\ttot_regret_mu, tot_regret_sigma = np.mean(df[[\"f_regret_total\"]].to_numpy()),np.std(df[[\"f_regret_total\"]].to_numpy())\n",
    "\t\n",
    "\tdf = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='1' and surrogate='{surrogate}'\", cnx)\n",
    "\tregret_r_mu, regret_r_sigma = np.mean(df[[\"f_regret\"]].to_numpy()),np.std(df[[\"f_regret\"]].to_numpy())\n",
    "\ttot_regret_r_mu, tot_regret_r_sigma = np.mean(df[[\"f_regret_total\"]].to_numpy()),np.std(df[[\"f_regret_total\"]].to_numpy())\n",
    "\t\n",
    "\tprint(f\"{surrogate} | {cal_mu:.2E} +/- {cal_sigma:.2E} | {regret_mu:.2E} +/- {regret_sigma:.2E} , {regret_r_mu:.2E} +/- {regret_r_sigma:.2E} | {tot_regret_mu:.2E} +/- {tot_regret_sigma:.2E} , {tot_regret_r_mu:.2E} +/- {tot_regret_r_sigma:.2E}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figs.scripts.loader import Loader\n",
    "from imports.general import *\n",
    "from imports.ml import *\n",
    "loader = Loader()\n",
    "loader.path2sql([\"results_change_std\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figs.scripts.loader import Loader\n",
    "from imports.general import *\n",
    "from imports.ml import *\n",
    "loader = Loader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# for recal in [False,True]:\n",
    "#     for group in groups_:\n",
    "#         out = \"f_regret\"\n",
    "#         r_f = pd.read_sql(loader.dict2query(,table_name=table_name, columns=[out]))[[out]].to_numpy()\n",
    "\n",
    "#         tr_f = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='0' and surrogate='{sur}'  and snr='{snr}'\", cnx)[[\"f_regret_total\"]].to_numpy()\n",
    "#         c_r = pd.read_sql(f\"select * from {folders[0]} where bo='0' and recalibrate='0' and surrogate='{sur}'  and snr='{snr}'\", cnx)[[\"y_calibration_mse\"]].to_numpy()\n",
    "#         c_bo = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='0' and surrogate='{sur}'  and snr='{snr}'\", cnx)[[\"y_calibration_mse\"]].to_numpy()\n",
    "\n",
    "#         c_r_r = pd.read_sql(f\"select * from {folders[0]} where bo='0' and recalibrate='1' and surrogate='{sur}'  and snr='{snr}'\", cnx)[[\"y_calibration_mse\"]].to_numpy()\n",
    "#         c_bo_r = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='1' and surrogate='{sur}'  and snr='{snr}'\", cnx)[[\"y_calibration_mse\"]].to_numpy()\n",
    "#         r_f_r = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='1' and surrogate='{sur}'  and snr='{snr}' \", cnx)[[\"f_regret\"]].to_numpy()\n",
    "#         tr_f_r = pd.read_sql(f\"select * from {folders[0]} where bo='1' and recalibrate='1' and surrogate='{sur}'  and snr='{snr}' \", cnx)[[\"f_regret_total\"]].to_numpy()\n",
    "\n",
    "#         row = f\"{sur} \" +(\n",
    "#                 f\"&$\"\n",
    "#                 + format_num(np.nanmean(c_bo_r))\n",
    "#                 + \"\\,\\,(\\pm \"\n",
    "#                 + format_num(np.nanstd(c_bo_r))\n",
    "#                 + \")$\"\n",
    "#             )\n",
    "#     if False and sur not in [\"RS\", \"DS\"]:\n",
    "        # row += (\n",
    "        #     \"&$\"\n",
    "        #     + format_num(np.nanmean(c_r))\n",
    "        #     + \"\\,\\,(\\pm \"\n",
    "        #     + format_num(np.nanstd(c_r))\n",
    "        #     + \")$\"\n",
    "        # )\n",
    "        # row += (\n",
    "        #     \"&$\"\n",
    "        #     + format_num(np.nanmean(c_bo))\n",
    "        #     + \"\\,\\,(\\pm \"\n",
    "        #     + format_num(np.nanstd(c_bo))\n",
    "        #     + \")$\"\n",
    "        # )\n",
    "    #     row += (\n",
    "    #         f\"&$\"\n",
    "    #         + format_num(np.nanmean(r_f))\n",
    "    #         + \"\\,\\,(\\pm \"\n",
    "    #         + format_num(np.nanstd(r_f))\n",
    "    #         + \")$\"\n",
    "    #     )\n",
    "    #     row += (\n",
    "    #         f\"&$\"\n",
    "    #         + format_num(np.nanmean(r_f_r))\n",
    "    #         + \"\\,\\,(\\pm \"\n",
    "    #         + format_num(np.nanstd(r_f_r))\n",
    "    #         + \")$\"\n",
    "    #     )\n",
    "    #     row += (\n",
    "    #         f\"&$\"\n",
    "    #         + format_num(np.nanmean(tr_f))\n",
    "    #         + \"\\,\\,(\\pm \"\n",
    "    #         + format_num(np.nanstd(tr_f))\n",
    "    #         + \")$\"\n",
    "    #     )\n",
    "    #     row += (\n",
    "    #         f\"&$\"\n",
    "    #         + format_num(np.nanmean(tr_f_r))\n",
    "    #         + \"\\,\\,(\\pm \"\n",
    "    #         + format_num(np.nanstd(tr_f_r))\n",
    "    #         + \")$\"\n",
    "    #     )\n",
    "    # else:\n",
    "    #     pass\n",
    "    #     # row += \"-&\"+ (\n",
    "    #     #     f\"&$\"\n",
    "    #     #     + format_num(np.nanmean(r_f))\n",
    "    #     #     + \"\\,\\,(\\pm \"\n",
    "    #     #     + format_num(np.nanstd(r_f))\n",
    "    #     #     + \")$\"\n",
    "    #     # ) +\"-&-&-&-\"\n",
    "    # print(row )#+ \"\\\\\\\\\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from figs.scripts.loader import Loader\n",
    "from figs.scripts.tables import Tables\n",
    "from figs.scripts.figures import Figures\n",
    "from imports.general import *\n",
    "from imports.ml import *\n",
    "\n",
    "tables = Tables()\n",
    "figures = Figures()\n",
    "# # For paper:\n",
    "# Tabel 1:\n",
    "tables.table_linear_correlation()\n",
    "# Tabel 2:\n",
    "tables.table_linear_model(X_bo=False)\n",
    "# Tabel 3:\n",
    "tables.table_linear_model(X_bo=True)\n",
    "# Figure 1:\n",
    "figures.figure_regret_calibration(settings_x = {\"bo\": True, \"metric\": \"f_regret\"},\n",
    "        settings_y = {\"bo\": True, \"metric\": \"y_calibration_mse\"},\n",
    "        x_figsettings= {\"label\": r\"$\\mathcal{R}_I(f)$\", \"log\": True},\n",
    "        y_figsettings= {\"label\": r\"$\\mathcal{C}_{BO}(y)$\", \"log\": True},)\n",
    "\n",
    "figures.figure_regret_calibration(settings_x = {\"bo\": True, \"metric\": \"f_regret\"},\n",
    "        settings_y = {\"bo\": False, \"metric\": \"y_calibration_mse\"},\n",
    "        x_figsettings= {\"label\": r\"$\\mathcal{R}_I(f)$\", \"log\": True},\n",
    "        y_figsettings= {\"label\": r\"$\\mathcal{C}_{R}(y)$\", \"log\": True},)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Change in predictive std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT y_calibration_mse FROM results_change_std WHERE data_name='benchmark' and epoch='90' and snr='100' and bo='0' and surrogate='BNN' and std_change='0.01';\n",
      "SELECT y_calibration_mse FROM results_change_std WHERE data_name='benchmark' and epoch='90' and snr='100' and bo='0' and surrogate='BNN' and std_change='0.1';\n",
      "SELECT y_calibration_mse FROM results_change_std WHERE data_name='benchmark' and epoch='90' and snr='100' and bo='0' and surrogate='BNN' and std_change='0.1414';\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'int' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1966c7ff808d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mfigs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscripts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFigures\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfigures\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFigures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m figures.figure_std_vs_metric(settings={\n\u001b[0m\u001b[1;32m      4\u001b[0m             \u001b[0;34m\"data_name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m\"benchmark\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0;34m\"epoch\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m90\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Dropbox/DTU/phd/code/unibo/figs/scripts/figures.py\u001b[0m in \u001b[0;36mfigure_std_vs_metric\u001b[0;34m(self, x, y, groups, settings, table_name)\u001b[0m\n\u001b[1;32m    478\u001b[0m                 \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_sql\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mdata_mu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m                 \u001b[0mdata_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m             plt.errorbar(\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36mnanmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m    948\u001b[0m     \u001b[0mcnt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m     \u001b[0mtot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 950\u001b[0;31m     \u001b[0mavg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_divide_by_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    951\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    952\u001b[0m     \u001b[0misbad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/ml/lib/python3.9/site-packages/numpy/lib/nanfunctions.py\u001b[0m in \u001b[0;36m_divide_by_count\u001b[0;34m(a, b, out)\u001b[0m\n\u001b[1;32m    215\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    218\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0;31m# This is questionable, but currently a numpy scalar can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'int' object has no attribute 'dtype'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x432 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from figs.scripts.figures import Figures\n",
    "figures = Figures()\n",
    "# figures.figure_std_vs_metric(settings={\n",
    "#             \"data_name\": \"benchmark\",\n",
    "#             \"epoch\": 90,\n",
    "#             \"snr\": 100,\n",
    "#             \"bo\": False,\n",
    "#         })\n",
    "figures.figure_std_vs_metric(settings={\n",
    "            \"data_name\": \"benchmark\",\n",
    "            \"epoch\": 90,\n",
    "            \"snr\": 100,\n",
    "            \"bo\": True,\n",
    "        })\n",
    "figures.figure_std_vs_metric(settings={\n",
    "            \"data_name\": \"benchmark\",\n",
    "            \"epoch\": 90,\n",
    "            \"snr\": 100,\n",
    "            \"bo\": True,\n",
    "        },y = \"f_regret\")\n",
    "figures.scatter_regret_calibration_std_change(average=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.geomspace(0.1,1.2, 21))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. The effect of the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imports.general import *\n",
    "from imports.ml import *\n",
    "from experiments.samples import SamplesExperiment\n",
    "from scipy.special import erf,erfinv\n",
    "# exp = SamplesExperiment()\n",
    "# exp.run()\n",
    "\n",
    "def g(p,v, mu_t=None):\n",
    "\tif mu_t is None:\n",
    "\t\treturn 1/2*(1 + erf(v*erfinv(2*p-1)))\n",
    "\telse:\n",
    "\t\treturn 1/2*(1 + erf(mu_t/np.sqrt(2) + v*erfinv(2*p-1)))\n",
    "\n",
    "def g_approx(p,v):\t\n",
    "\tx = 2*p - 1\n",
    "\treturn p*x + 1/3*(v-v**3)*x + 1/15*v*(2*v**4 - 5*v**2 + 3)*x**5\n",
    "\n",
    "\n",
    "p = np.linspace(0.001,1,100)\n",
    "v = np.linspace(0.1,2,10)\n",
    "colors = plt.cm.plasma(np.linspace(0, 1, len(v)))\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Correct mean\")\n",
    "plt.plot(p,p,\"--\")\n",
    "for i_v,v_ in enumerate(v):\n",
    "\tgs = []\n",
    "\tg_appoxs = []\n",
    "\tfor p_ in p:\n",
    "\t\tgs.append(g(p_,v_))\n",
    "\t\tg_appoxs.append(g_approx(p_,v_))\n",
    "\tif i_v == len(v)-1 or i_v == 0:\n",
    "\t\tplt.plot(p,gs,color=colors[i_v],label=v_)\n",
    "\telse:\n",
    "\t\tplt.plot(p,gs,color=colors[i_v])\n",
    "\t# plt.plot(p,g_appoxs,\"--\",color=colors[i_v])\n",
    "plt.xlabel(\"Expected percentiles (p)\")\n",
    "plt.ylabel(\"Observed percentiles\")\n",
    "plt.legend()\n",
    "\n",
    "for mu in [-2.0,2.0]:\n",
    "\tplt.figure()\n",
    "\tplt.plot(p,p,\"--\")\n",
    "\tplt.title(f\"Mean:{mu}\")\n",
    "\tfor i_v,v_ in enumerate(v):\n",
    "\t\tgs = []\n",
    "\t\tfor p_ in p:\n",
    "\t\t\tgs.append(g(p_,v_,mu_t=mu))\n",
    "\t\tif i_v == len(v)-1 or i_v == 0:\n",
    "\t\t\tplt.plot(p,gs,color=colors[i_v],label=v_)\n",
    "\t\telse:\n",
    "\t\t\tplt.plot(p,gs,color=colors[i_v])\n",
    "\tplt.legend()\n",
    "\tplt.xlabel(\"Expected percentiles (p)\")\n",
    "\tplt.ylabel(\"Observed percentiles\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Recalibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.parameters import Parameters\n",
    "from src.recalibrator import Recalibrator\n",
    "from src.dataset import Dataset\n",
    "from src.metrics import Metrics\n",
    "from surrogates.gaussian_process import GaussianProcess\n",
    "\n",
    "parameters = Parameters({\"surrogate\":\"RF\",\n",
    "\"experiment\":\"1\",\n",
    "\"acquisition\":\"EI\",\n",
    "\"data_name\":\"benchmark\",\n",
    "\"n_evals\":50,\n",
    "\"n_test\":1000,\n",
    "\"snr\":10,\n",
    "\"xi\":0.0,\n",
    "\"bo\":True,\n",
    "\"problem_idx\":3, \n",
    "\"d\":1,\n",
    "\"seed\":0 ,\n",
    "\"n_initial\":10},mkdir=True)\n",
    "\n",
    "dataset = Dataset(parameters)\n",
    "model = GaussianProcess(parameters,dataset)\n",
    "recalibrator = Recalibrator(dataset,model,mode=\"iid\")\n",
    "\n",
    "model.fit(dataset.data.X_train,dataset.data.y_train)\n",
    "\n",
    "idx = np.argsort(dataset.data.X_test.squeeze())\n",
    "X_test = dataset.data.X_test[idx]\n",
    "y_test = dataset.data.y_test[idx]\n",
    "mus_,sigmas_ = model.predict(X_test)\n",
    "mus_ = mus_.squeeze()\n",
    "sigmas_ = sigmas_.squeeze()\n",
    "fig = plt.figure()\n",
    "plt.plot(X_test, mus_, marker=\".\")\n",
    "plt.fill_between(X_test.squeeze(), mus_-2*sigmas_,mus_+2*sigmas_,alpha=0.2)\n",
    "plt.plot(X_test, y_test,\"x\",alpha=0.2)\n",
    "plt.plot(dataset.data.X_train, dataset.data.y_train,\"o\")\n",
    "\n",
    "mus,sigmas = recalibrator.recalibrate(mus_,sigmas_)\n",
    "fig = plt.figure()\n",
    "plt.plot(X_test, mus, marker=\".\")\n",
    "plt.fill_between(X_test.squeeze(), mus-2*sigmas,mus+2*sigmas,alpha=0.2)\n",
    "plt.plot(X_test, y_test,\"x\",alpha=0.2)\n",
    "plt.plot(dataset.data.X_train, dataset.data.y_train,\"o\")\n",
    "\n",
    "metrics = Metrics(parameters)\n",
    "\n",
    "metrics.calibration_y_batched(mus_,sigmas_,y_test)\n",
    "y_calibration_bef = metrics.summary[\"y_calibration\"]\n",
    "\n",
    "metrics.calibration_y_batched(mus,sigmas,y_test)\n",
    "y_calibration_aft = metrics.summary[\"y_calibration\"]\n",
    "\n",
    "fig = plt.figure()\n",
    "plt.plot(metrics.summary[\"p_array\"],metrics.summary[\"p_array\"],\"--\")\n",
    "plt.plot(metrics.summary[\"p_array\"],y_calibration_bef,\"-x\",label=\"Before\")\n",
    "plt.plot(metrics.summary[\"p_array\"],y_calibration_aft,\"-s\",label=\"After\")\n",
    "plt.legend(); plt.xlabel(r\"Expected Confidence Interval\"); plt.ylabel(\"Observed Confidence Interval\");\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. New loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_num(x: float,n: int):\n",
    "\tif n == 2:\n",
    "\t\treturn f\"{x:.2f}\"\n",
    "\tif n == 3:\n",
    "\t\treturn f\"{x:.3f}\"\n",
    "\tif n == 4:\n",
    "\t\treturn f\"{x:.4f}\"\n",
    "\n",
    "cnx = sqlite3.connect('./results.db')\n",
    "table_exists = cnx.execute(\n",
    "\t\tf\"SELECT name FROM sqlite_master WHERE type='table' AND name='{loaddir}';\"\n",
    ")\n",
    "\n",
    "y = \"f_regret\"\n",
    "for surrogate in [\"BNN\",\"GP\",\"RF\",\"DE\"]:\n",
    "\tdf = pd.read_sql(f\"select {y} from results_recalibrated_regret_vs_calibration where surrogate='{surrogate}'\", cnx)\n",
    "\tmu, std = format_num(df.mean().to_numpy().squeeze(),n=4),format_num(df.std().to_numpy().squeeze(),n=2)\n",
    "\tprint(surrogate,\"calibrated\",f\"${mu}\\,\\,(\\pm {std})$\")\n",
    "\tdf = pd.read_sql(f\"select {y} from results_regret_vs_calibration where surrogate='{surrogate}' and bo='1'\", cnx)\n",
    "\tmu, std = format_num(df.mean().to_numpy().squeeze(),n=4),format_num(df.std().to_numpy().squeeze(),n=2)\n",
    "\tprint(surrogate,\"not calibrated\",f\"${mu}\\,\\,(\\pm {std})$\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python scipy ks test:\n",
    "# akkumuleret/CDF fordeling fra ét y vs. empirisk akkumuleret fordeling"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31d7989649452b8ff5b252a3e34caf45e4ffd8a5787fe28fc2ce0245f11b7782"
  },
  "kernelspec": {
   "display_name": "Python 3.9.4 ('ml')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
